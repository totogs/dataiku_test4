{
  "metadata": {
    "kernelspec": {
      "name": "py-dku-containerized-venv-asl_alphabet-gpu_gke_2",
      "display_name": "Python in gpu_gke_2 (env asl_alphabet)",
      "language": "python"
    },
    "associatedRecipe": "compute_predictions",
    "creator": "tony",
    "createdOn": 1629799405892,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "tony"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 1,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\n\n# Read recipe inputs\njson_prepared \u003d dataiku.Dataset(\"Json_prepared\")\ndf \u003d json_prepared.get_dataframe()\n\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 2,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import math\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import Sequence\nfrom datetime import timedelta\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nimport numpy as np\nimport pandas as pd\nimport time\n\nimport os"
      ],
      "outputs": []
    },
    {
      "execution_count": 4,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "    Timestamp                      date  broker-102/  broker-104/  broker-106/  broker-108/  broker-110/  zook-102/  zook-104/  broker-102/data  broker-104/data  broker-106/data  broker-108/data  broker-110/data  zook-102/data  zook-104/data  broker-101/  broker-103/  broker-105/  broker-107/  broker-109/  zook-101/  zook-103/  zook-105/  broker-101/data  broker-103/data  broker-105/data  broker-107/data  broker-109/data  zook-101/data  zook-103/data  zook-105/data\n0  1624601700 2021-06-25 06:15:00+00:00    16.318256    14.317784    15.499574    13.478442    10.100069   3.457606   3.497103        85.198139        74.491702        70.937154        73.322070        88.858424       0.278296       0.216338    15.759843    15.526538    10.510089    13.464054     9.834396   3.489473   3.470773   3.176120        81.194161        76.236908        73.175427        72.768512        90.265277       0.251977       0.236909       0.245222\n1  1624602600 2021-06-25 06:30:00+00:00    16.201163    14.317455    15.596986    13.478452    10.100073   3.457596   3.498734        85.195519        74.540221        70.971025        73.390322        88.953916       0.278296       0.216338    15.798915    15.604688    10.588215    13.542199     9.893027   3.469877   3.470783   3.176225        81.216755        76.227287        73.233565        72.715046        90.343407       0.251977       0.236909       0.245222\n2  1624603500 2021-06-25 06:45:00+00:00    16.240144    14.200271    15.479296    13.478466    10.021952   3.457639   3.498534        85.368338        74.687954        71.060131        73.450625        89.056802       0.278296       0.216338    15.875768    15.526571    10.480893    13.464078     9.971639   3.489372   3.470907   3.156653        81.287027        76.350551        73.217323        72.744789        90.583015       0.251977       0.236909       0.245222\n3  1624604400 2021-06-25 07:00:00+00:00    16.166954    14.239343    15.479368    13.351567    10.002428   3.458865   3.498543        85.503684        74.622017        71.028285        73.530478        89.180835       0.278296       0.216338    15.875782    15.487523    10.519952    13.464083     9.971339   3.470134   3.470964   3.176167        81.417682        76.318796        73.396165        72.921757        90.711837       0.251977       0.236909       0.245222\n4  1624605300 2021-06-25 07:15:00+00:00    16.240354    14.317498    15.597000    13.405028    10.002437   3.497909   3.499302        85.652764        74.762854        71.062395        73.475029        89.232812       0.278296       0.216338    15.758903    15.458370    10.446685    13.542228     9.893218   3.470191   3.472156   3.176158        81.569016        76.359671        73.456350        72.810311        90.751683       0.251977       0.236909       0.245222",
            "text/html": "\n            \u003cbutton style\u003d\"display:none\" \n            class\u003d\"btn btn-default ipython-export-btn\" \n            id\u003d\"btn-df-1a7a82c9-d0c9-4f8d-8cef-c110b159e017\" \n            onclick\u003d\"_export_df(\u00271a7a82c9-d0c9-4f8d-8cef-c110b159e017\u0027)\"\u003e\n                Export dataframe\n            \u003c/button\u003e\n            \n            \u003cscript\u003e\n                \n                function _check_export_df_possible(dfid,yes_fn,no_fn) {\n                    console.log(\u0027Checking dataframe exportability...\u0027)\n                    if(!IPython || !IPython.notebook || !IPython.notebook.kernel || !IPython.notebook.kernel) {\n                        console.log(\u0027Export is not possible (IPython kernel is not available)\u0027)\n                        if(no_fn) {\n                            no_fn();\n                        }\n                    } else {\n                        var pythonCode \u003d \u0027from dataiku.notebook.export import IPythonExporter;IPythonExporter._check_export_stdout(\"\u0027+dfid+\u0027\")\u0027;\n                        IPython.notebook.kernel.execute(pythonCode,{iopub: {output: function(resp) {\n                            console.info(\"Exportability response\", resp);\n                            var size \u003d /^([0-9]+)x([0-9]+)$/.exec(resp.content.data || resp.content.text)\n                            if(!size) {\n                                console.log(\u0027Export is not possible (dataframe is not in-memory anymore)\u0027)\n                                if(no_fn) {\n                                    no_fn();\n                                }\n                            } else {\n                                console.log(\u0027Export is possible\u0027)\n                                if(yes_fn) {\n                                    yes_fn(1*size[1],1*size[2]);\n                                }\n                            }\n                        }}});\n                    }\n                }\n            \n                function _export_df(dfid) {\n                    \n                    var btn \u003d $(\u0027#btn-df-\u0027+dfid);\n                    var btns \u003d $(\u0027.ipython-export-btn\u0027);\n                    \n                    _check_export_df_possible(dfid,function() {\n                        \n                        window.parent.openExportModalFromIPython(\u0027Pandas dataframe\u0027,function(data) {\n                            btns.prop(\u0027disabled\u0027,true);\n                            btn.text(\u0027Exporting...\u0027);\n                            var command \u003d \u0027from dataiku.notebook.export import IPythonExporter;IPythonExporter._run_export(\"\u0027+dfid+\u0027\",\"\u0027+data.exportId+\u0027\")\u0027;\n                            var callback \u003d {iopub:{output: function(resp) {\n                                console.info(\"CB resp:\", resp);\n                                _check_export_df_possible(dfid,function(rows, cols) {\n                                    $(\u0027#btn-df-\u0027+dfid)\n                                        .css(\u0027display\u0027,\u0027inline-block\u0027)\n                                        .text(\u0027Export this dataframe (\u0027+rows+\u0027 rows, \u0027+cols+\u0027 cols)\u0027)\n                                        .prop(\u0027disabled\u0027,false);\n                                },function() {\n                                    $(\u0027#btn-df-\u0027+dfid).css(\u0027display\u0027,\u0027none\u0027);\n                                });\n                            }}};\n                            IPython.notebook.kernel.execute(command,callback,{silent:false}); // yes, silent now defaults to true. figures.\n                        });\n                    \n                    }, function(){\n                            alert(\u0027Unable to export : the Dataframe object is not loaded in memory\u0027);\n                            btn.css(\u0027display\u0027,\u0027none\u0027);\n                    });\n                    \n                }\n                \n                (function(dfid) {\n                \n                    var retryCount \u003d 10;\n                \n                    function is_valid_websock(s) {\n                        return s \u0026\u0026 s.readyState\u003d\u003d1;\n                    }\n                \n                    function check_conn() {\n                        \n                        if(!IPython || !IPython.notebook) {\n                            // Don\u0027t even try to go further\n                            return;\n                        }\n                        \n                        // Check if IPython is ready\n                        console.info(\"Checking conn ...\")\n                        if(IPython.notebook.kernel\n                        \u0026\u0026 IPython.notebook.kernel\n                        \u0026\u0026 is_valid_websock(IPython.notebook.kernel.ws)\n                        ) {\n                            \n                            _check_export_df_possible(dfid,function(rows, cols) {\n                                $(\u0027#btn-df-\u0027+dfid).css(\u0027display\u0027,\u0027inline-block\u0027);\n                                $(\u0027#btn-df-\u0027+dfid).text(\u0027Export this dataframe (\u0027+rows+\u0027 rows, \u0027+cols+\u0027 cols)\u0027);\n                            });\n                            \n                        } else {\n                            console.info(\"Conditions are not ok\", IPython.notebook.kernel);\n                            \n                            // Retry later\n                            \n                            if(retryCount\u003e0) {\n                                setTimeout(check_conn,500);\n                                retryCount--;\n                            }\n                            \n                        }\n                    };\n                    \n                    setTimeout(check_conn,100);\n                    \n                })(\"1a7a82c9-d0c9-4f8d-8cef-c110b159e017\");\n                \n            \u003c/script\u003e\n            \n        \u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style\u003d\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eTimestamp\u003c/th\u003e\n      \u003cth\u003edate\u003c/th\u003e\n      \u003cth\u003ebroker-102/\u003c/th\u003e\n      \u003cth\u003ebroker-104/\u003c/th\u003e\n      \u003cth\u003ebroker-106/\u003c/th\u003e\n      \u003cth\u003ebroker-108/\u003c/th\u003e\n      \u003cth\u003ebroker-110/\u003c/th\u003e\n      \u003cth\u003ezook-102/\u003c/th\u003e\n      \u003cth\u003ezook-104/\u003c/th\u003e\n      \u003cth\u003ebroker-102/data\u003c/th\u003e\n      \u003cth\u003ebroker-104/data\u003c/th\u003e\n      \u003cth\u003ebroker-106/data\u003c/th\u003e\n      \u003cth\u003ebroker-108/data\u003c/th\u003e\n      \u003cth\u003ebroker-110/data\u003c/th\u003e\n      \u003cth\u003ezook-102/data\u003c/th\u003e\n      \u003cth\u003ezook-104/data\u003c/th\u003e\n      \u003cth\u003ebroker-101/\u003c/th\u003e\n      \u003cth\u003ebroker-103/\u003c/th\u003e\n      \u003cth\u003ebroker-105/\u003c/th\u003e\n      \u003cth\u003ebroker-107/\u003c/th\u003e\n      \u003cth\u003ebroker-109/\u003c/th\u003e\n      \u003cth\u003ezook-101/\u003c/th\u003e\n      \u003cth\u003ezook-103/\u003c/th\u003e\n      \u003cth\u003ezook-105/\u003c/th\u003e\n      \u003cth\u003ebroker-101/data\u003c/th\u003e\n      \u003cth\u003ebroker-103/data\u003c/th\u003e\n      \u003cth\u003ebroker-105/data\u003c/th\u003e\n      \u003cth\u003ebroker-107/data\u003c/th\u003e\n      \u003cth\u003ebroker-109/data\u003c/th\u003e\n      \u003cth\u003ezook-101/data\u003c/th\u003e\n      \u003cth\u003ezook-103/data\u003c/th\u003e\n      \u003cth\u003ezook-105/data\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e1624601700\u003c/td\u003e\n      \u003ctd\u003e2021-06-25 06:15:00+00:00\u003c/td\u003e\n      \u003ctd\u003e16.318256\u003c/td\u003e\n      \u003ctd\u003e14.317784\u003c/td\u003e\n      \u003ctd\u003e15.499574\u003c/td\u003e\n      \u003ctd\u003e13.478442\u003c/td\u003e\n      \u003ctd\u003e10.100069\u003c/td\u003e\n      \u003ctd\u003e3.457606\u003c/td\u003e\n      \u003ctd\u003e3.497103\u003c/td\u003e\n      \u003ctd\u003e85.198139\u003c/td\u003e\n      \u003ctd\u003e74.491702\u003c/td\u003e\n      \u003ctd\u003e70.937154\u003c/td\u003e\n      \u003ctd\u003e73.322070\u003c/td\u003e\n      \u003ctd\u003e88.858424\u003c/td\u003e\n      \u003ctd\u003e0.278296\u003c/td\u003e\n      \u003ctd\u003e0.216338\u003c/td\u003e\n      \u003ctd\u003e15.759843\u003c/td\u003e\n      \u003ctd\u003e15.526538\u003c/td\u003e\n      \u003ctd\u003e10.510089\u003c/td\u003e\n      \u003ctd\u003e13.464054\u003c/td\u003e\n      \u003ctd\u003e9.834396\u003c/td\u003e\n      \u003ctd\u003e3.489473\u003c/td\u003e\n      \u003ctd\u003e3.470773\u003c/td\u003e\n      \u003ctd\u003e3.176120\u003c/td\u003e\n      \u003ctd\u003e81.194161\u003c/td\u003e\n      \u003ctd\u003e76.236908\u003c/td\u003e\n      \u003ctd\u003e73.175427\u003c/td\u003e\n      \u003ctd\u003e72.768512\u003c/td\u003e\n      \u003ctd\u003e90.265277\u003c/td\u003e\n      \u003ctd\u003e0.251977\u003c/td\u003e\n      \u003ctd\u003e0.236909\u003c/td\u003e\n      \u003ctd\u003e0.245222\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e1624602600\u003c/td\u003e\n      \u003ctd\u003e2021-06-25 06:30:00+00:00\u003c/td\u003e\n      \u003ctd\u003e16.201163\u003c/td\u003e\n      \u003ctd\u003e14.317455\u003c/td\u003e\n      \u003ctd\u003e15.596986\u003c/td\u003e\n      \u003ctd\u003e13.478452\u003c/td\u003e\n      \u003ctd\u003e10.100073\u003c/td\u003e\n      \u003ctd\u003e3.457596\u003c/td\u003e\n      \u003ctd\u003e3.498734\u003c/td\u003e\n      \u003ctd\u003e85.195519\u003c/td\u003e\n      \u003ctd\u003e74.540221\u003c/td\u003e\n      \u003ctd\u003e70.971025\u003c/td\u003e\n      \u003ctd\u003e73.390322\u003c/td\u003e\n      \u003ctd\u003e88.953916\u003c/td\u003e\n      \u003ctd\u003e0.278296\u003c/td\u003e\n      \u003ctd\u003e0.216338\u003c/td\u003e\n      \u003ctd\u003e15.798915\u003c/td\u003e\n      \u003ctd\u003e15.604688\u003c/td\u003e\n      \u003ctd\u003e10.588215\u003c/td\u003e\n      \u003ctd\u003e13.542199\u003c/td\u003e\n      \u003ctd\u003e9.893027\u003c/td\u003e\n      \u003ctd\u003e3.469877\u003c/td\u003e\n      \u003ctd\u003e3.470783\u003c/td\u003e\n      \u003ctd\u003e3.176225\u003c/td\u003e\n      \u003ctd\u003e81.216755\u003c/td\u003e\n      \u003ctd\u003e76.227287\u003c/td\u003e\n      \u003ctd\u003e73.233565\u003c/td\u003e\n      \u003ctd\u003e72.715046\u003c/td\u003e\n      \u003ctd\u003e90.343407\u003c/td\u003e\n      \u003ctd\u003e0.251977\u003c/td\u003e\n      \u003ctd\u003e0.236909\u003c/td\u003e\n      \u003ctd\u003e0.245222\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e1624603500\u003c/td\u003e\n      \u003ctd\u003e2021-06-25 06:45:00+00:00\u003c/td\u003e\n      \u003ctd\u003e16.240144\u003c/td\u003e\n      \u003ctd\u003e14.200271\u003c/td\u003e\n      \u003ctd\u003e15.479296\u003c/td\u003e\n      \u003ctd\u003e13.478466\u003c/td\u003e\n      \u003ctd\u003e10.021952\u003c/td\u003e\n      \u003ctd\u003e3.457639\u003c/td\u003e\n      \u003ctd\u003e3.498534\u003c/td\u003e\n      \u003ctd\u003e85.368338\u003c/td\u003e\n      \u003ctd\u003e74.687954\u003c/td\u003e\n      \u003ctd\u003e71.060131\u003c/td\u003e\n      \u003ctd\u003e73.450625\u003c/td\u003e\n      \u003ctd\u003e89.056802\u003c/td\u003e\n      \u003ctd\u003e0.278296\u003c/td\u003e\n      \u003ctd\u003e0.216338\u003c/td\u003e\n      \u003ctd\u003e15.875768\u003c/td\u003e\n      \u003ctd\u003e15.526571\u003c/td\u003e\n      \u003ctd\u003e10.480893\u003c/td\u003e\n      \u003ctd\u003e13.464078\u003c/td\u003e\n      \u003ctd\u003e9.971639\u003c/td\u003e\n      \u003ctd\u003e3.489372\u003c/td\u003e\n      \u003ctd\u003e3.470907\u003c/td\u003e\n      \u003ctd\u003e3.156653\u003c/td\u003e\n      \u003ctd\u003e81.287027\u003c/td\u003e\n      \u003ctd\u003e76.350551\u003c/td\u003e\n      \u003ctd\u003e73.217323\u003c/td\u003e\n      \u003ctd\u003e72.744789\u003c/td\u003e\n      \u003ctd\u003e90.583015\u003c/td\u003e\n      \u003ctd\u003e0.251977\u003c/td\u003e\n      \u003ctd\u003e0.236909\u003c/td\u003e\n      \u003ctd\u003e0.245222\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e1624604400\u003c/td\u003e\n      \u003ctd\u003e2021-06-25 07:00:00+00:00\u003c/td\u003e\n      \u003ctd\u003e16.166954\u003c/td\u003e\n      \u003ctd\u003e14.239343\u003c/td\u003e\n      \u003ctd\u003e15.479368\u003c/td\u003e\n      \u003ctd\u003e13.351567\u003c/td\u003e\n      \u003ctd\u003e10.002428\u003c/td\u003e\n      \u003ctd\u003e3.458865\u003c/td\u003e\n      \u003ctd\u003e3.498543\u003c/td\u003e\n      \u003ctd\u003e85.503684\u003c/td\u003e\n      \u003ctd\u003e74.622017\u003c/td\u003e\n      \u003ctd\u003e71.028285\u003c/td\u003e\n      \u003ctd\u003e73.530478\u003c/td\u003e\n      \u003ctd\u003e89.180835\u003c/td\u003e\n      \u003ctd\u003e0.278296\u003c/td\u003e\n      \u003ctd\u003e0.216338\u003c/td\u003e\n      \u003ctd\u003e15.875782\u003c/td\u003e\n      \u003ctd\u003e15.487523\u003c/td\u003e\n      \u003ctd\u003e10.519952\u003c/td\u003e\n      \u003ctd\u003e13.464083\u003c/td\u003e\n      \u003ctd\u003e9.971339\u003c/td\u003e\n      \u003ctd\u003e3.470134\u003c/td\u003e\n      \u003ctd\u003e3.470964\u003c/td\u003e\n      \u003ctd\u003e3.176167\u003c/td\u003e\n      \u003ctd\u003e81.417682\u003c/td\u003e\n      \u003ctd\u003e76.318796\u003c/td\u003e\n      \u003ctd\u003e73.396165\u003c/td\u003e\n      \u003ctd\u003e72.921757\u003c/td\u003e\n      \u003ctd\u003e90.711837\u003c/td\u003e\n      \u003ctd\u003e0.251977\u003c/td\u003e\n      \u003ctd\u003e0.236909\u003c/td\u003e\n      \u003ctd\u003e0.245222\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e1624605300\u003c/td\u003e\n      \u003ctd\u003e2021-06-25 07:15:00+00:00\u003c/td\u003e\n      \u003ctd\u003e16.240354\u003c/td\u003e\n      \u003ctd\u003e14.317498\u003c/td\u003e\n      \u003ctd\u003e15.597000\u003c/td\u003e\n      \u003ctd\u003e13.405028\u003c/td\u003e\n      \u003ctd\u003e10.002437\u003c/td\u003e\n      \u003ctd\u003e3.497909\u003c/td\u003e\n      \u003ctd\u003e3.499302\u003c/td\u003e\n      \u003ctd\u003e85.652764\u003c/td\u003e\n      \u003ctd\u003e74.762854\u003c/td\u003e\n      \u003ctd\u003e71.062395\u003c/td\u003e\n      \u003ctd\u003e73.475029\u003c/td\u003e\n      \u003ctd\u003e89.232812\u003c/td\u003e\n      \u003ctd\u003e0.278296\u003c/td\u003e\n      \u003ctd\u003e0.216338\u003c/td\u003e\n      \u003ctd\u003e15.758903\u003c/td\u003e\n      \u003ctd\u003e15.458370\u003c/td\u003e\n      \u003ctd\u003e10.446685\u003c/td\u003e\n      \u003ctd\u003e13.542228\u003c/td\u003e\n      \u003ctd\u003e9.893218\u003c/td\u003e\n      \u003ctd\u003e3.470191\u003c/td\u003e\n      \u003ctd\u003e3.472156\u003c/td\u003e\n      \u003ctd\u003e3.176158\u003c/td\u003e\n      \u003ctd\u003e81.569016\u003c/td\u003e\n      \u003ctd\u003e76.359671\u003c/td\u003e\n      \u003ctd\u003e73.456350\u003c/td\u003e\n      \u003ctd\u003e72.810311\u003c/td\u003e\n      \u003ctd\u003e90.751683\u003c/td\u003e\n      \u003ctd\u003e0.251977\u003c/td\u003e\n      \u003ctd\u003e0.236909\u003c/td\u003e\n      \u003ctd\u003e0.245222\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 5,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n# Split into training, validation and test datasets.\n# Since it\u0027s timeseries we should do it by date.\ntest_cutoff_date \u003d df[\u0027date\u0027].max() - timedelta(days\u003d7)\nval_cutoff_date \u003d test_cutoff_date - timedelta(days\u003d14)\n\ndf_test \u003d df[df[\u0027date\u0027] \u003e test_cutoff_date]\ndf_val \u003d df[(df[\u0027date\u0027] \u003e val_cutoff_date) \u0026 (df[\u0027date\u0027] \u003c\u003d test_cutoff_date)]\ndf_train \u003d df[df[\u0027date\u0027] \u003c\u003d val_cutoff_date]\n\n#check out the datasets\nprint(\u0027Test dates: {} to {}\u0027.format(df_test[\u0027date\u0027].min(), df_test[\u0027date\u0027].max()))\nprint(\u0027Validation dates: {} to {}\u0027.format(df_val[\u0027date\u0027].min(), df_val[\u0027date\u0027].max()))\nprint(\u0027Train dates: {} to {}\u0027.format(df_train[\u0027date\u0027].min(), df_train[\u0027date\u0027].max()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "Test dates: 2021-07-29 13:15:00+00:00 to 2021-08-05 13:00:00+00:00\nValidation dates: 2021-07-15 13:15:00+00:00 to 2021-07-29 13:00:00+00:00\nTrain dates: 2021-06-25 06:15:00+00:00 to 2021-07-15 13:00:00+00:00\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 6,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n# Goal of the model:\n#  Predict Global_active_power at a specified time in the future.\n#   Eg. We want to predict how much Global_active_power will be ten minutes from now.\n#       We can use all the values from t-1, t-2, t-3, .... t-history_length to predict t+10\n\n\ndef create_ts_files(dataset, \n                    start_index, \n                    end_index, \n                    history_length, \n                    step_size, \n                    target_step, \n                    num_rows_per_file, \n                    data_folder):\n    assert step_size \u003e 0\n    assert start_index \u003e\u003d 0\n    \n    if not os.path.exists(data_folder):\n        os.makedirs(data_folder)\n    \n    time_lags \u003d sorted(range(target_step+1, target_step+history_length+1, step_size), reverse\u003dTrue)\n    col_names \u003d [f\u0027x_lag{i}\u0027 for i in time_lags] + [\u0027y\u0027]\n    start_index \u003d start_index + history_length\n    if end_index is None:\n        end_index \u003d len(dataset) - target_step\n    \n    rng \u003d range(start_index, end_index)\n    num_rows \u003d len(rng)\n    num_files \u003d math.ceil(num_rows/num_rows_per_file)\n    \n    # for each file.\n    print(f\u0027Creating {num_files} files.\u0027)\n    for i in range(num_files):\n        filename \u003d f\u0027{data_folder}/ts_file{i}.pkl\u0027\n        \n        if i % 10 \u003d\u003d 0:\n            print(f\u0027{filename}\u0027)\n            \n        # get the start and end indices.\n        ind0 \u003d i*num_rows_per_file\n        ind1 \u003d min(ind0 + num_rows_per_file, end_index)\n        data_list \u003d []\n        \n        # j in the current timestep. Will need j-n to j-1 for the history. And j + target_step for the target.\n        for j in range(ind0, ind1):\n            indices \u003d range(j-1, j-history_length-1, -step_size)\n            data \u003d dataset[sorted(indices) + [j+target_step]]\n            \n            # append data to the list.\n            data_list.append(data)\n\n        df_ts \u003d pd.DataFrame(data\u003ddata_list, columns\u003dcol_names)\n        df_ts.to_pickle(filename)\n            \n    return len(col_names)-1"
      ],
      "outputs": []
    },
    {
      "execution_count": 7,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n%%time\n\nglobal_active_power \u003d df_train[\u0027Global_active_power\u0027].values\n\n# Scaled to work with Neural networks.\nscaler \u003d MinMaxScaler(feature_range\u003d(0, 1))\nglobal_active_power_scaled \u003d scaler.fit_transform(global_active_power.reshape(-1, 1)).reshape(-1, )\n\nhistory_length \u003d 7*24*60  # The history length in minutes.\nstep_size \u003d 10  # The sampling rate of the history. Eg. If step_size \u003d 1, then values from every minute will be in the history.\n                #                                       If step size \u003d 10 then values every 10 minutes will be in the history.\ntarget_step \u003d 10  # The time step in the future to predict. Eg. If target_step \u003d 0, then predict the next timestep after the end of the history period.\n                  #                                             If target_step \u003d 10 then predict 10 timesteps the next timestep (11 minutes after the end of history).\n\n# The csv creation returns the number of rows and number of features. We need these values below.\nnum_timesteps \u003d create_ts_files(global_active_power_scaled,\n                                start_index\u003d0,\n                                end_index\u003dNone,\n                                history_length\u003dhistory_length,\n                                step_size\u003dstep_size,\n                                target_step\u003dtarget_step,\n                                num_rows_per_file\u003d128*100,\n                                data_folder\u003d\u0027ts_data\u0027)\n\n# I found that the easiest way to do time series with tensorflow is by creating pandas files with the lagged time steps (eg. x{t-1}, x{t-2}...) and \n# the value to predict y \u003d x{t+n}. We tried doing it using TFRecords, but that API is not very intuitive and lacks working examples for time series.\n# The resulting file using these parameters is over 17GB. If history_length is increased, or  step_size is decreased, it could get much bigger.\n# Hard to fit into laptop memory, so need to use other means to load the data from the hard drive."
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\u0027Global_active_power\u0027",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/opt/dataiku/code-env/lib64/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \u0027Global_active_power\u0027",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m\u003ctimed exec\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/opt/dataiku/code-env/lib64/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m\u003e\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/dataiku/code-env/lib64/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m\u003d\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m\u003d\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m\u003e\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m\u003e\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \u0027Global_active_power\u0027"
          ]
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute recipe outputs from inputs\n# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n\npredictions_df \u003d json_prepared_df # For this sample code, simply copy input to output\n\n\n# Write recipe outputs\npredictions \u003d dataiku.Dataset(\"predictions\")\npredictions.write_with_schema(predictions_df)"
      ],
      "outputs": []
    }
  ]
}